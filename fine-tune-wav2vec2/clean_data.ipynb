{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f41a9d13",
   "metadata": {},
   "source": [
    "# pyannote/speaker-diarization-3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26bbcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files:   0%|          | 0/87139 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /opt/conda/conda-bld/pytorch_1708025847130/work/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "Processing audio files:   7%|▋         | 6033/87139 [06:40<2:20:12,  9.64it/s] "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Khởi tạo pipeline diarization với token HF\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"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\"\n",
    ").to(torch.device(\"cuda\"))\n",
    "\n",
    "# 2. Gốc thư mục chứa dữ liệu\n",
    "root_folder = \"/ASV/dataset/train_eval/data\"\n",
    "\n",
    "# 3. Thu thập tất cả các file .wav trong các thư mục con\n",
    "wav_files = []\n",
    "for dirpath, _, filenames in os.walk(root_folder):\n",
    "    for fname in filenames:\n",
    "        if fname.lower().endswith(\".wav\"):\n",
    "            wav_files.append(os.path.join(dirpath, fname))\n",
    "wav_files.sort()\n",
    "\n",
    "# 5. Xử lý từng file với tqdm\n",
    "output_path = \"speaker-diarization-result.txt\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    for wav_path in tqdm(wav_files, desc=\"Processing audio files\"):\n",
    "        try:\n",
    "            # 5.1 Chạy diarization\n",
    "            diarization = pipeline(wav_path)\n",
    "            # 5.2 Thu thập speaker turn\n",
    "            speakers = set()\n",
    "            for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "                speakers.add(speaker)\n",
    "\n",
    "            f.write(f\"{wav_path} {len(speakers)}\\n\")\n",
    "        except Exception as e:\n",
    "            fname = os.path.basename(wav_path)\n",
    "            print(f\"Lỗi khi xử lý {fname}: {e}\")\n",
    "\n",
    "print(f\"\\nĐã lưu kết quả vào {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1bcb2b",
   "metadata": {},
   "source": [
    "# pyannote/segmentation-3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf09929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyannote.audio import Model\n",
    "from pyannote.audio.pipelines import OverlappedSpeechDetection\n",
    "\n",
    "# 1. Load segmentation model\n",
    "segmentation_model = Model.from_pretrained(\n",
    "    \"pyannote/segmentation-3.0\",\n",
    "    use_auth_token=\"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\"\n",
    ")\n",
    "\n",
    "# 2. Khởi tạo pipeline OSD\n",
    "osd_pipeline = OverlappedSpeechDetection(segmentation=segmentation_model)\n",
    "HYPER_PARAMETERS = {\n",
    "    # Loại bỏ vùng overlap quá ngắn (nếu cần)a\n",
    "    \"min_duration_on\": 0.1,\n",
    "    # Điền vùng không-overlap ngắn (nếu cần)\n",
    "    \"min_duration_off\": 0.0\n",
    "}\n",
    "osd_pipeline.instantiate(HYPER_PARAMETERS)\n",
    "\n",
    "# 3. Thư mục chứa các file .wav cần kiểm tra\n",
    "spk_folder = \"/ASV/dataset/train_eval/data/id00000\"\n",
    "\n",
    "# 4. Danh sách file có speech overlap (nhiều người nói)\n",
    "multi_speaker_files = []\n",
    "\n",
    "# 5. Duyệt qua các file .wav\n",
    "for fname in os.listdir(spk_folder):\n",
    "    if not fname.lower().endswith(\".wav\"):\n",
    "        continue\n",
    "    wav_path = os.path.join(spk_folder, fname)\n",
    "    print(f\"Processing {fname}...\")\n",
    "\n",
    "    # 6. Chạy Overlapped Speech Detection\n",
    "    osd = osd_pipeline(wav_path)\n",
    "\n",
    "    # 7. Nếu pipeline trả về bất kỳ segment overlap nào → file có multi-speaker\n",
    "    if len(osd.get_timeline()) > 0:\n",
    "        multi_speaker_files.append(wav_path)\n",
    "\n",
    "# 8. In kết quả\n",
    "print(\"\\nFiles chứa chồng lấn (nhiều người nói cùng lúc):\")\n",
    "for f in multi_speaker_files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b09f000",
   "metadata": {},
   "source": [
    "# pyannote/overlapped-speech-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6cb428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "# 1. Thay YOUR_HF_TOKEN bằng token của bạn\n",
    "HF_TOKEN = \"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\"\n",
    "\n",
    "# 2. Khởi tạo pipeline Overlapped Speech Detection\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/overlapped-speech-detection\",\n",
    "    use_auth_token=HF_TOKEN\n",
    ")\n",
    "\n",
    "# 3. Thư mục chứa các file WAV cần kiểm tra\n",
    "spk_folder = \"/ASV/dataset/train_eval/data/id00000\"\n",
    "\n",
    "# 4. Danh sách file có overlapped speech\n",
    "multi_speaker_files = []\n",
    "\n",
    "# 5. Duyệt qua từng file WAV\n",
    "for fname in os.listdir(spk_folder):\n",
    "    if not fname.lower().endswith(\".wav\"):\n",
    "        continue\n",
    "\n",
    "    wav_path = os.path.join(spk_folder, fname)\n",
    "    print(f\"Processing {fname}...\")\n",
    "\n",
    "    # 6. Chạy pipeline\n",
    "    output = pipeline(wav_path)\n",
    "\n",
    "    # 7. Nếu có bất kỳ segment overlapped speech nào → thêm vào danh sách\n",
    "    #    output.get_timeline() trả về Timeline các đoạn speech overlap\n",
    "    if len(output.get_timeline()) > 0:\n",
    "        multi_speaker_files.append(fname)\n",
    "\n",
    "# 8. In kết quả\n",
    "print(\"\\nFiles chứa overlapped speech (≥2 speakers):\")\n",
    "for f in multi_speaker_files:\n",
    "    print(f\" - {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fecd085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyannote.audio import Model\n",
    "from pyannote.audio.pipelines import OverlappedSpeechDetection\n",
    "\n",
    "# 1. Load segmentation model\n",
    "segmentation_model = Model.from_pretrained(\n",
    "    \"pyannote/segmentation-3.0\",\n",
    "    use_auth_token=\"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\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "# 2. Khởi tạo pipeline OSD với ngưỡng overlap ≥ 0.1s\n",
    "osd_pipeline = OverlappedSpeechDetection(segmentation=segmentation_model)\n",
    "HYPER_PARAMETERS = {\n",
    "    \"min_duration_on\": 0.2,   # bỏ overlap ngắn dưới 100ms\n",
    "    \"min_duration_off\": 0.0\n",
    "}\n",
    "osd_pipeline.instantiate(HYPER_PARAMETERS)\n",
    "\n",
    "# 3. Thư mục gốc chứa mọi folder con\n",
    "root_folder = \"/ASV/dataset/train_eval/data\"\n",
    "\n",
    "# 4. Danh sách các file .wav có speech overlap\n",
    "multi_speaker_files = []\n",
    "\n",
    "# 5. Duyệt đệ quy toàn bộ cây thư mục\n",
    "for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "    for fname in filenames:\n",
    "        if not fname.lower().endswith(\".wav\"):\n",
    "            continue\n",
    "        wav_path = os.path.join(dirpath, fname)\n",
    "        print(f\"Processing {wav_path}...\")\n",
    "        \n",
    "        # 6. Chạy Overlapped Speech Detection\n",
    "        osd = osd_pipeline(wav_path)\n",
    "\n",
    "        # 7. Nếu có bất kỳ segment overlap nào → file multi-speaker\n",
    "        if len(osd.get_timeline()) > 0:\n",
    "            multi_speaker_files.append(wav_path)\n",
    "\n",
    "# 8. In kết quả\n",
    "print(\"\\n=== Files chứa overlapped speech (≥2 speakers) ===\")\n",
    "for f in multi_speaker_files:\n",
    "    print(f\" - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4dcaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Lưu kết quả vào file\n",
    "multi_speaker_files.sort()\n",
    "output_path = \"multi_speaker_files.txt\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    for path in multi_speaker_files:\n",
    "        f.write(f\"{path}\\n\")\n",
    "\n",
    "print(f\"\\nĐã lưu danh sách vào {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdas = osd_pipeline(\"/ASV/dataset/train_eval/data/id00002/00034.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdas.get_timeline().__len__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
